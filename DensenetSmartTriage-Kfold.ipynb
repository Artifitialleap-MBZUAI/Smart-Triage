{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"DensenetSmartTriage-Kfold.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"Y04rYVmZ8bwf"},"source":["import os\n","import tensorflow as tf\n","import numpy as np #adds support for large, multi-dimensional arrays and matrices, along with a large collection of high-level mathematical functions to operate on these arrays\n","import pandas as pd #data structures and operations for manipulating numerical tables and time series\n","import sys # system path io\n","import glob #glob module is used to retrieve files/pathnames matching a specified pattern\n","from tqdm import tqdm # show progress bar when a loop is running\n","from plotly.offline import download_plotlyjs, init_notebook_mode, iplot\n","from plotly import tools\n","from plotly.graph_objs import *\n","from plotly.graph_objs.layout import Margin, YAxis, XAxis\n","init_notebook_mode()\n","import matplotlib.pyplot as plt\n","from matplotlib import patches as patches\n","from pathlib import Path\n","import xml.etree.ElementTree as ET\n","from keras.callbacks import EarlyStopping\n","from sklearn.metrics import accuracy_score, f1_score, precision_score, confusion_matrix\n","from keras.applications.densenet import DenseNet121, preprocess_input\n","from sklearn.model_selection import KFold, StratifiedKFold\n","from keras.applications.mobilenet_v2 import MobileNetV2,preprocess_input\n","from keras.applications.mobilenet import MobileNet,preprocess_input\n","from keras.preprocessing import image\n","from keras.preprocessing.image import ImageDataGenerator\n","from keras import optimizers\n","from keras import backend as K\n","import io\n","from google.colab import drive\n","from sklearn.model_selection import KFold, StratifiedKFold,LeaveOneOut\n","from keras.layers import Input, Lambda, Dense, Flatten\n","from keras.models import Model\n","from keras.preprocessing import image\n","from keras.preprocessing.image import ImageDataGenerator\n","from keras import optimizers\n","from keras import backend as K\n","from keras.callbacks import EarlyStopping\n","import shutil\n","import statistics\n","from keras.models import Model\n","from tensorflow.keras import layers\n","drive.mount('/content/gdrive')\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Structure: Diagnosis, Triage_Level\n","#NEED TO CODE FOR THE ZERO TRIAGE SCORE!\n","#Not real scores!\n","LookUp_Dictionary  = {\n","  'burns1':1,\n","  'burns2': 2,\n","  'burns3':10 ,\n","  'BacterialInfections': 5, \n","  'NailDiseases':2 ,\n","  'ContactDermatitis':6,\n","  'UrticariaHives':3,\n","  'Others':0,\n","  'wounds': 7,\n","  'ViralInfections':5\n","}\n","print(LookUp_Dictionary)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UbPA-ZWIS9I8","executionInfo":{"status":"ok","timestamp":1646225172821,"user_tz":300,"elapsed":10,"user":{"displayName":"yaser khamayseh","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14587607702986936428"}},"outputId":"d94acebc-6ad6-4abb-d845-02da40894e0b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["{'burns1': 1, 'burns2': 2, 'burns3': 10, 'BacterialInfections': 5, 'NailDiseases': 2, 'ContactDermatitis': 6, 'UrticariaHives': 3, 'Others': 0, 'wounds': 7, 'ViralInfections': 5}\n"]}]},{"cell_type":"code","metadata":{"id":"EsjJaP62lPop","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1646225202885,"user_tz":300,"elapsed":5666,"user":{"displayName":"yaser khamayseh","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14587607702986936428"}},"outputId":"afce52cf-03bb-4705-d383-06118d9a6b84"},"source":["IMAGE_SIZE=[250,250]\n","batch_size=32\n","NN  = DenseNet121(input_shape=IMAGE_SIZE + [3], weights='imagenet', include_top=False)  \n","#MobileNet(input_shape=IMAGE_SIZE + [3], weights='imagenet', include_top=False)   \n","for layer in NN.layers:\n","    layer.trainable = False\n","# layers creation - Here more can be added\n","x = layers.Flatten()(NN.output)\n","x = layers.Dense(1000, activation='relu')(x)\n","prediction = layers.Dense(10, activation='softmax')(x)\n","# creating a model object\n","model = Model(inputs=NN.input, outputs=prediction)\n","sgd = tf.keras.optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n","model.compile(\n","  loss='categorical_crossentropy',\n","\n","  optimizer='sgd',\n","\n","  metrics=['accuracy'] \n","\n",")"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/densenet/densenet121_weights_tf_dim_ordering_tf_kernels_notop.h5\n","29089792/29084464 [==============================] - 0s 0us/step\n","29097984/29084464 [==============================] - 0s 0us/step\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning:\n","\n","The `lr` argument is deprecated, use `learning_rate` instead.\n","\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mecACg4VpiZN","outputId":"25b75c67-e63d-4e16-f2d9-486e4dcd57e9","executionInfo":{"status":"ok","timestamp":1646225230776,"user_tz":300,"elapsed":25526,"user":{"displayName":"yaser khamayseh","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14587607702986936428"}}},"source":["import PIL\n","X=[]\n","Y=[]\n","base_dir=\"/content/gdrive/MyDrive/MBZUAI/Smart Triage/Potential Datasets/SkinBurns\"\n","labels_list=['burns2','burns1','burns3','BacterialInfections', 'NailDiseases','ContactDermatitis','UrticariaHives','Others','wounds','ViralInfections']\n","dir=os.getcwd()\n","for directory in labels_list:\n","    print(directory)\n","    #print(len(os.listdir(base_dir+'/'+directory)))\n","    for files in os.listdir(base_dir+'/'+directory):\n","        #img = Image.open(directory+'/'+files)\n","        #img = img.convert('L')\n","        #img = img.resize((IMG_SIZE, IMG_SIZE), Image.ANTIALIAS)\n","        X.append(directory+'/'+files)\n","        #X.append([np.array(img)])\n","        current_index=labels_list.index(directory)\n","        Y.append(current_index)\n","X=np.asarray(X)\n","Y=np.asarray(Y)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["burns2\n","burns1\n","burns3\n","BacterialInfections\n","NailDiseases\n","ContactDermatitis\n","UrticariaHives\n","Others\n","wounds\n","ViralInfections\n"]}]},{"cell_type":"code","source":["!mkdir  validation\n","!mkdir  validation/burns2\n","!mkdir  validation/burns1\n","!mkdir  validation/burns3\n","!mkdir  validation/BacterialInfections\n","!mkdir  validation/NailDiseases\n","!mkdir  validation/ContactDermatitis\n","!mkdir  validation/UrticariaHives\n","!mkdir  validation/Others\n","!mkdir  validation/wounds\n","!mkdir  validation/ViralInfections"],"metadata":{"id":"mLGJM0s51nVa"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YUHxbVIsj_T5","colab":{"base_uri":"https://localhost:8080/"},"outputId":"9e71ac6b-f2ce-425a-e804-788aa4c54b02","executionInfo":{"status":"ok","timestamp":1646230128707,"user_tz":300,"elapsed":4896785,"user":{"displayName":"yaser khamayseh","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14587607702986936428"}}},"source":["#kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=7)\n","cvscores = []\n","\n","validation_path=\"validation\"\n","train_path= '/content/gdrive/MyDrive/MBZUAI/Smart Triage/Potential Datasets/SkinBurns/'\n","#skf = StratifiedKFold(n_splits=2, shuffle=True)\n","#skf.get_n_splits(X, Y)\n","accuracy_list= list()\n","precision_list=list()\n","f1_list=list()\n","microprecision_list=list()\n","microf1_list=list()\n","means, mins, maxs = list(),list(),list()\n","f1means, f1mins, f1maxs = list(),list(),list()\n","microf1means, microf1mins, microf1maxs = list(),list(),list()\n","precmeans, precmins, precmaxs = list(),list(),list()\n","microprecmeans, microprecmins, microprecmaxs = list(),list(),list()\n","\n","callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=7,min_delta=.001,mode='auto')\n","foldNum=0\n","k=5\n","skf = StratifiedKFold(n_splits=k, shuffle=True)\n","\n","for train_index, val_index in skf.split(X, Y):\n","             \n","       foldNum+=1\n","       model.compile(loss='categorical_crossentropy', optimizer='sgd',  metrics=['accuracy'] )\n","       print(\"Results for fold\",foldNum)\n","       X_train, X_val = X[train_index], X[val_index]\n","       Y_train, Y_val = Y[train_index], Y[val_index]\n","       for eachindex in range(len(X_val)):\n","           shutil.move('/content/gdrive/MyDrive/MBZUAI/Smart Triage/Potential Datasets/SkinBurns/'+X_val[eachindex], \n","                    'validation/'+X_val[eachindex])\n","       \n","       #Start ImageClassification Model\n","       train_datagen = ImageDataGenerator(rotation_range=20, horizontal_flip=True,  vertical_flip=True, brightness_range=[0.7,1.2], preprocessing_function=preprocess_input)\n","\n","       validation_datagen = ImageDataGenerator( preprocessing_function=preprocess_input)\n","       train_generator = train_datagen.flow_from_directory(\n","            train_path,\n","            shuffle= True,\n","            target_size=IMAGE_SIZE,\n","            batch_size=32,\n","            subset='training')\n","       validation_generator = validation_datagen.flow_from_directory(\n","            validation_path,\n","            target_size=IMAGE_SIZE,\n","            batch_size=32,\n","            shuffle=False)  \n","       \n","       #history=\n","       model.fit(train_generator, \n","                        epochs=40,\n","                        validation_data = validation_generator,\n","                        steps_per_epoch=int(len(X_train) // batch_size),\n","                        validation_steps=int(len(X_val) // batch_size),\n","                        callbacks=[callback])\n","       predictions = model.predict(validation_generator, verbose=1)\n","       #score = model.evaluate(validation_generator,batch_size =32)\n","       #print('eval', score)\n","       yPredictions = np.argmax(predictions, axis=1)\n","       true_classes = validation_generator.classes\n","       # evaluate validation performance\n","       #print(\"***Performance on Validation data***\")\n","       accuracy=accuracy_score(true_classes, yPredictions)\n","       f1=f1_score(true_classes, yPredictions,average='macro')\n","       microf1= f1_score(true_classes, yPredictions,average='micro')\n","       precision= precision_score(true_classes, yPredictions,average='macro')\n","       microprecision= precision_score(true_classes, yPredictions,average='micro')\n","       #precision=precision_score(true_classes, yPredictions,average='weighted')\n","       #f1Score=f1_score(true_classes, yPredictions, average='weighted') \n","       #print(\"Accuracy  : {}\".format(accuracy))\n","       #print(\"Precision : {}\".format(precision))\n","       #print(\"f1Score : {}\".format(f1Score))\n","       #cm=confusion_matrix(true_classes, yPredictions)\n","       accuracy_list.append(accuracy)\n","       f1_list.append(f1)\n","       precision_list.append(precision)\n","       microf1_list.append(microf1)\n","       microprecision_list.append(microprecision)\n","       #print(cm)\n","       #valAcc, valPrec, valFScore = my_metrics(true_classes, yPredictions)\n","       for returnindex in range(len(X_val)):\n","            shutil.move('validation/'+X_val[returnindex],'/content/gdrive/MyDrive/MBZUAI/Smart Triage/Potential Datasets/SkinBurns/'+X_val[returnindex])\n","#gotta change this to F1\n","k_mean=statistics.mean(accuracy_list)\n","k_max=max(accuracy_list)\n","k_min=min(accuracy_list)\n","means.append(k_mean)\n","mins.append(k_mean - k_min)\n","maxs.append(k_max - k_mean)\n","#==================\n","f1_mean=statistics.mean(f1_list)\n","f1_max=max(f1_list)\n","f1_min=min(f1_list)\n","f1means.append(f1_mean)\n","f1mins.append(f1_mean - f1_min)\n","f1maxs.append(f1_max - f1_mean)\n","#========================\n","prec_mean=statistics.mean(precision_list)\n","prec_max=max(precision_list)\n","prec_min=min(precision_list)\n","precmeans.append(prec_mean)\n","precmins.append(prec_mean - prec_min)\n","precmaxs.append(prec_max - prec_mean)\n","#==========================\n","microprec_mean=statistics.mean(microprecision_list)\n","microprec_max=max(microprecision_list)\n","microprec_min=min(microprecision_list)\n","microprecmeans.append(microprec_mean)\n","microprecmins.append(microprec_mean - microprec_min)\n","microprecmaxs.append(microprec_max - microprec_mean)\n","#===========================\n","microf1_mean=statistics.mean(microf1_list)\n","microf1_max=max(microf1_list)\n","microf1_min=min(microf1_list)\n","microf1means.append(microf1_mean)\n","microf1mins.append(microf1_mean - microf1_min)\n","microf1maxs.append(microf1_max - microf1_mean)\n","\n","print('Image_size and batch_size')\n","print(IMAGE_SIZE,batch_size)\n","print('Minimum Accuracy')\n","print(mins)\n","print('Maximum Accuracy')\n","print(maxs)\n","print('Average Accuracy')\n","print(means)\n","#=============\n","print('Minimum macro precision')\n","print(precmins)\n","print('Maximum macro precision')\n","print(precmaxs)\n","print('Average macro precision')\n","print(precmeans)\n","#===============\n","print('Minimum macro F1')\n","print(f1mins)\n","print('Maximum macro F1')\n","print(f1maxs)\n","print('Average macro F1')\n","print(f1means)\n","#===============\n","print('Minimum micro precision')\n","print(microprecmins)\n","print('Maximum micro precision')\n","print(microprecmaxs)\n","print('Average micro precision')\n","print(microprecmeans)\n","#===============\n","print('Minimum micro F1')\n","print(microf1mins)\n","print('Maximum micro F1')\n","print(microf1maxs)\n","print('Average micro F1')\n","print(microf1means)\n","#plt.errorbar(folds, means, yerr=[mins, maxs], fmt='o')\n","# plot the ideal case in a separate color\n","#plt.plot(folds, [ideal for _ in range(len(folds))], color='r')\n","# show the plot\n","#plt.show()\n","   #model.fit_generator(train_generator, epochs=50,  verbose = 0, validation_data=test_generator)\n","\n","   #scores = model.evaluate(X[test], Y[test], verbose=0)\n","   #print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n","\n","\n"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Results for fold 1\n","Found 2465 images belonging to 10 classes.\n","Found 617 images belonging to 10 classes.\n","Epoch 1/40\n","77/77 [==============================] - 1411s 18s/step - loss: 2.7018 - accuracy: 0.4879 - val_loss: 1.0494 - val_accuracy: 0.6151\n","Epoch 2/40\n","77/77 [==============================] - 56s 721ms/step - loss: 1.0076 - accuracy: 0.6321 - val_loss: 1.3009 - val_accuracy: 0.5395\n","Epoch 3/40\n","77/77 [==============================] - 55s 721ms/step - loss: 0.8427 - accuracy: 0.6901 - val_loss: 0.8748 - val_accuracy: 0.6497\n","Epoch 4/40\n","77/77 [==============================] - 55s 717ms/step - loss: 0.7826 - accuracy: 0.7078 - val_loss: 0.8922 - val_accuracy: 0.6579\n","Epoch 5/40\n","77/77 [==============================] - 56s 727ms/step - loss: 0.6794 - accuracy: 0.7386 - val_loss: 0.7569 - val_accuracy: 0.6957\n","Epoch 6/40\n","77/77 [==============================] - 56s 724ms/step - loss: 0.6304 - accuracy: 0.7567 - val_loss: 0.7751 - val_accuracy: 0.6859\n","Epoch 7/40\n","77/77 [==============================] - 55s 721ms/step - loss: 0.5668 - accuracy: 0.7818 - val_loss: 0.7913 - val_accuracy: 0.7007\n","Epoch 8/40\n","77/77 [==============================] - 55s 721ms/step - loss: 0.5562 - accuracy: 0.7813 - val_loss: 0.9465 - val_accuracy: 0.7072\n","Epoch 9/40\n","77/77 [==============================] - 56s 726ms/step - loss: 0.5103 - accuracy: 0.8118 - val_loss: 0.9113 - val_accuracy: 0.7072\n","Epoch 10/40\n","77/77 [==============================] - 56s 730ms/step - loss: 0.4852 - accuracy: 0.8105 - val_loss: 0.8959 - val_accuracy: 0.6842\n","Epoch 11/40\n","77/77 [==============================] - 56s 720ms/step - loss: 0.4651 - accuracy: 0.8290 - val_loss: 0.8242 - val_accuracy: 0.6908\n","Epoch 12/40\n","77/77 [==============================] - 55s 721ms/step - loss: 0.4311 - accuracy: 0.8303 - val_loss: 0.7876 - val_accuracy: 0.6908\n","20/20 [==============================] - 6s 236ms/step\n","Results for fold 2\n","Found 2464 images belonging to 10 classes.\n","Found 618 images belonging to 10 classes.\n","Epoch 1/40\n","77/77 [==============================] - 64s 755ms/step - loss: 0.5192 - accuracy: 0.8060 - val_loss: 0.4214 - val_accuracy: 0.8487\n","Epoch 2/40\n","77/77 [==============================] - 57s 738ms/step - loss: 0.4635 - accuracy: 0.8247 - val_loss: 0.4152 - val_accuracy: 0.8421\n","Epoch 3/40\n","77/77 [==============================] - 56s 733ms/step - loss: 0.4592 - accuracy: 0.8308 - val_loss: 0.4617 - val_accuracy: 0.8141\n","Epoch 4/40\n","77/77 [==============================] - 57s 739ms/step - loss: 0.4194 - accuracy: 0.8421 - val_loss: 0.3876 - val_accuracy: 0.8618\n","Epoch 5/40\n","77/77 [==============================] - 57s 734ms/step - loss: 0.3846 - accuracy: 0.8596 - val_loss: 0.4402 - val_accuracy: 0.8339\n","Epoch 6/40\n","77/77 [==============================] - 56s 732ms/step - loss: 0.3476 - accuracy: 0.8644 - val_loss: 0.4256 - val_accuracy: 0.8339\n","Epoch 7/40\n","77/77 [==============================] - 56s 730ms/step - loss: 0.3598 - accuracy: 0.8685 - val_loss: 0.4341 - val_accuracy: 0.8454\n","Epoch 8/40\n","77/77 [==============================] - 57s 735ms/step - loss: 0.3054 - accuracy: 0.8843 - val_loss: 0.4602 - val_accuracy: 0.8388\n","Epoch 9/40\n","77/77 [==============================] - 56s 727ms/step - loss: 0.2803 - accuracy: 0.9046 - val_loss: 0.4186 - val_accuracy: 0.8586\n","Epoch 10/40\n","77/77 [==============================] - 56s 728ms/step - loss: 0.2943 - accuracy: 0.8904 - val_loss: 0.4153 - val_accuracy: 0.8503\n","Epoch 11/40\n","77/77 [==============================] - 56s 733ms/step - loss: 0.2504 - accuracy: 0.9140 - val_loss: 0.4401 - val_accuracy: 0.8520\n","20/20 [==============================] - 6s 241ms/step\n","Results for fold 3\n","Found 2465 images belonging to 10 classes.\n","Found 617 images belonging to 10 classes.\n","Epoch 1/40\n","77/77 [==============================] - 64s 763ms/step - loss: 0.3247 - accuracy: 0.8792 - val_loss: 0.2701 - val_accuracy: 0.9062\n","Epoch 2/40\n","77/77 [==============================] - 57s 735ms/step - loss: 0.3053 - accuracy: 0.8890 - val_loss: 0.2528 - val_accuracy: 0.9128\n","Epoch 3/40\n","77/77 [==============================] - 57s 734ms/step - loss: 0.2862 - accuracy: 0.8981 - val_loss: 0.2357 - val_accuracy: 0.9145\n","Epoch 4/40\n","77/77 [==============================] - 57s 737ms/step - loss: 0.2419 - accuracy: 0.9149 - val_loss: 0.2049 - val_accuracy: 0.9293\n","Epoch 5/40\n","77/77 [==============================] - 56s 733ms/step - loss: 0.2337 - accuracy: 0.9157 - val_loss: 0.2111 - val_accuracy: 0.9342\n","Epoch 6/40\n","77/77 [==============================] - 57s 738ms/step - loss: 0.3946 - accuracy: 0.8841 - val_loss: 0.3647 - val_accuracy: 0.8405\n","Epoch 7/40\n","77/77 [==============================] - 57s 737ms/step - loss: 0.2414 - accuracy: 0.9125 - val_loss: 0.2708 - val_accuracy: 0.8997\n","Epoch 8/40\n","77/77 [==============================] - 57s 735ms/step - loss: 0.2032 - accuracy: 0.9264 - val_loss: 0.2602 - val_accuracy: 0.9062\n","Epoch 9/40\n","77/77 [==============================] - 56s 728ms/step - loss: 0.2500 - accuracy: 0.9125 - val_loss: 0.2838 - val_accuracy: 0.8849\n","Epoch 10/40\n","77/77 [==============================] - 56s 730ms/step - loss: 0.1822 - accuracy: 0.9342 - val_loss: 0.2784 - val_accuracy: 0.8914\n","Epoch 11/40\n","77/77 [==============================] - 56s 728ms/step - loss: 0.2214 - accuracy: 0.9215 - val_loss: 0.2780 - val_accuracy: 0.8799\n","20/20 [==============================] - 6s 219ms/step\n","Results for fold 4\n","Found 2468 images belonging to 10 classes.\n","Found 614 images belonging to 10 classes.\n","Epoch 1/40\n","77/77 [==============================] - 62s 747ms/step - loss: 0.2233 - accuracy: 0.9167 - val_loss: 0.1401 - val_accuracy: 0.9523\n","Epoch 2/40\n","77/77 [==============================] - 56s 724ms/step - loss: 0.2096 - accuracy: 0.9265 - val_loss: 0.1655 - val_accuracy: 0.9391\n","Epoch 3/40\n","77/77 [==============================] - 56s 731ms/step - loss: 0.1746 - accuracy: 0.9401 - val_loss: 0.1612 - val_accuracy: 0.9391\n","Epoch 4/40\n","77/77 [==============================] - 56s 726ms/step - loss: 0.1951 - accuracy: 0.9323 - val_loss: 0.1394 - val_accuracy: 0.9490\n","Epoch 5/40\n","77/77 [==============================] - 56s 723ms/step - loss: 0.1719 - accuracy: 0.9417 - val_loss: 0.1297 - val_accuracy: 0.9507\n","Epoch 6/40\n","77/77 [==============================] - 56s 728ms/step - loss: 0.1495 - accuracy: 0.9475 - val_loss: 0.1356 - val_accuracy: 0.9424\n","Epoch 7/40\n","77/77 [==============================] - 57s 735ms/step - loss: 0.1709 - accuracy: 0.9380 - val_loss: 0.1357 - val_accuracy: 0.9507\n","Epoch 8/40\n","77/77 [==============================] - 56s 725ms/step - loss: 0.1382 - accuracy: 0.9573 - val_loss: 0.1549 - val_accuracy: 0.9375\n","Epoch 9/40\n","77/77 [==============================] - 56s 722ms/step - loss: 0.1444 - accuracy: 0.9544 - val_loss: 0.1526 - val_accuracy: 0.9441\n","Epoch 10/40\n","77/77 [==============================] - 56s 723ms/step - loss: 0.1296 - accuracy: 0.9569 - val_loss: 0.1830 - val_accuracy: 0.9424\n","Epoch 11/40\n","77/77 [==============================] - 56s 723ms/step - loss: 0.1215 - accuracy: 0.9602 - val_loss: 0.1509 - val_accuracy: 0.9457\n","Epoch 12/40\n","77/77 [==============================] - 57s 745ms/step - loss: 0.1094 - accuracy: 0.9667 - val_loss: 0.1598 - val_accuracy: 0.9441\n","20/20 [==============================] - 7s 251ms/step\n","Results for fold 5\n","Found 2466 images belonging to 10 classes.\n","Found 616 images belonging to 10 classes.\n","Epoch 1/40\n","77/77 [==============================] - 63s 755ms/step - loss: 0.1244 - accuracy: 0.9597 - val_loss: 0.0966 - val_accuracy: 0.9704\n","Epoch 2/40\n","77/77 [==============================] - 57s 736ms/step - loss: 0.1149 - accuracy: 0.9622 - val_loss: 0.1098 - val_accuracy: 0.9655\n","Epoch 3/40\n","77/77 [==============================] - 56s 733ms/step - loss: 0.1313 - accuracy: 0.9515 - val_loss: 0.1119 - val_accuracy: 0.9572\n","Epoch 4/40\n","77/77 [==============================] - 56s 725ms/step - loss: 0.0990 - accuracy: 0.9663 - val_loss: 0.1275 - val_accuracy: 0.9490\n","Epoch 5/40\n","77/77 [==============================] - 55s 718ms/step - loss: 0.1003 - accuracy: 0.9675 - val_loss: 0.1353 - val_accuracy: 0.9539\n","Epoch 6/40\n","77/77 [==============================] - 56s 734ms/step - loss: 0.0948 - accuracy: 0.9655 - val_loss: 0.1283 - val_accuracy: 0.9572\n","Epoch 7/40\n","77/77 [==============================] - 56s 725ms/step - loss: 0.0795 - accuracy: 0.9717 - val_loss: 0.1086 - val_accuracy: 0.9688\n","Epoch 8/40\n","77/77 [==============================] - 56s 720ms/step - loss: 0.0800 - accuracy: 0.9758 - val_loss: 0.1270 - val_accuracy: 0.9572\n","20/20 [==============================] - 7s 261ms/step\n","Image_size and batch_size\n","[250, 250] 32\n","Minimum Accuracy\n","[0.17145455413201027]\n","Maximum Accuracy\n","[0.09103781573475178]\n","Average Accuracy\n","[0.866754392057456]\n","Minimum macro precision\n","[0.1796767480549054]\n","Maximum macro precision\n","[0.08271218768774513]\n","Average macro precision\n","[0.8761734212338185]\n","Minimum macro F1\n","[0.19495536746985864]\n","Maximum macro F1\n","[0.08337158637939701]\n","Average macro F1\n","[0.8658733858942369]\n","Minimum micro precision\n","[0.17145455413201027]\n","Maximum micro precision\n","[0.09103781573475178]\n","Average micro precision\n","[0.866754392057456]\n","Minimum micro F1\n","[0.17145455413201027]\n","Maximum micro F1\n","[0.09103781573475178]\n","Average micro F1\n","[0.866754392057456]\n"]}]},{"cell_type":"markdown","source":["Image_size and batch_size\n","[250, 250] 32\n","Minimum Accuracy\n","[0.17145455413201027]\n","Maximum Accuracy\n","[0.09103781573475178]\n","Average Accuracy\n","[0.866754392057456]\n","Minimum macro precision\n","[0.1796767480549054]\n","Maximum macro precision\n","[0.08271218768774513]\n","Average macro precision\n","[0.8761734212338185]\n","Minimum macro F1\n","[0.19495536746985864]\n","Maximum macro F1\n","[0.08337158637939701]\n","Average macro F1\n","[0.8658733858942369]\n","Minimum micro precision\n","[0.17145455413201027]\n","Maximum micro precision\n","[0.09103781573475178]\n","Average micro precision\n","[0.866754392057456]\n","Minimum micro F1\n","[0.17145455413201027]\n","Maximum micro F1\n","[0.09103781573475178]\n","Average micro F1\n","[0.866754392057456]"],"metadata":{"id":"PTIOcqv9dONP"}}]}