{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"ResNetSmartTriage-Kfold.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"Y04rYVmZ8bwf","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1646240349363,"user_tz":300,"elapsed":21266,"user":{"displayName":"yaser khamayseh","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14587607702986936428"}},"outputId":"1b9d3973-382b-4558-df76-93c7a2cac29c"},"source":["import os\n","import tensorflow as tf\n","import numpy as np #adds support for large, multi-dimensional arrays and matrices, along with a large collection of high-level mathematical functions to operate on these arrays\n","import pandas as pd #data structures and operations for manipulating numerical tables and time series\n","import sys # system path io\n","import glob #glob module is used to retrieve files/pathnames matching a specified pattern\n","from tqdm import tqdm # show progress bar when a loop is running\n","from plotly.offline import download_plotlyjs, init_notebook_mode, iplot\n","from plotly import tools\n","from plotly.graph_objs import *\n","from plotly.graph_objs.layout import Margin, YAxis, XAxis\n","init_notebook_mode()\n","import matplotlib.pyplot as plt\n","from matplotlib import patches as patches\n","from pathlib import Path\n","import xml.etree.ElementTree as ET\n","from keras.callbacks import EarlyStopping\n","from sklearn.metrics import accuracy_score, f1_score, precision_score, confusion_matrix\n","from keras.applications.densenet import DenseNet121, preprocess_input\n","from keras.applications.resnet import ResNet50, preprocess_input\n","from sklearn.model_selection import KFold, StratifiedKFold\n","from keras.applications.mobilenet_v2 import MobileNetV2,preprocess_input\n","from keras.applications.mobilenet import MobileNet,preprocess_input\n","from keras.preprocessing import image\n","from keras.preprocessing.image import ImageDataGenerator\n","from keras import optimizers\n","from keras import backend as K\n","import io\n","from google.colab import drive\n","from sklearn.model_selection import KFold, StratifiedKFold,LeaveOneOut\n","from keras.layers import Input, Lambda, Dense, Flatten\n","from keras.models import Model\n","from keras.preprocessing import image\n","from keras.preprocessing.image import ImageDataGenerator\n","from keras import optimizers\n","from keras import backend as K\n","from keras.callbacks import EarlyStopping\n","import shutil\n","import statistics\n","from keras.models import Model\n","from tensorflow.keras import layers\n","drive.mount('/content/gdrive')\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Structure: Diagnosis, Triage_Level\n","#NEED TO CODE FOR THE ZERO TRIAGE SCORE!\n","#Not real scores!\n","LookUp_Dictionary  = {\n","  'burns1':1,\n","  'burns2': 2,\n","  'burns3':10 ,\n","  'BacterialInfections': 5, \n","  'NailDiseases':2 ,\n","  'ContactDermatitis':6,\n","  'UrticariaHives':3,\n","  'Others':0,\n","  'wounds': 7,\n","  'ViralInfections':5\n","}\n","print(LookUp_Dictionary)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UbPA-ZWIS9I8","executionInfo":{"status":"ok","timestamp":1646231445898,"user_tz":300,"elapsed":12,"user":{"displayName":"yaser khamayseh","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14587607702986936428"}},"outputId":"a9fff7fd-0889-4fcb-fcb9-be546093ad7a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["{'burns1': 1, 'burns2': 2, 'burns3': 10, 'BacterialInfections': 5, 'NailDiseases': 2, 'ContactDermatitis': 6, 'UrticariaHives': 3, 'Others': 0, 'wounds': 7, 'ViralInfections': 5}\n"]}]},{"cell_type":"code","metadata":{"id":"EsjJaP62lPop","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1646240355024,"user_tz":300,"elapsed":5668,"user":{"displayName":"yaser khamayseh","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14587607702986936428"}},"outputId":"f0650da8-ec76-47e1-eb3a-d85711e85347"},"source":["IMAGE_SIZE=[250,250]\n","batch_size=32\n","NN  = ResNet50(input_shape=IMAGE_SIZE + [3], weights='imagenet', include_top=False)  \n","#MobileNet(input_shape=IMAGE_SIZE + [3], weights='imagenet', include_top=False)   \n","for layer in NN.layers:\n","    layer.trainable = False\n","# layers creation - Here more can be added\n","x = layers.Flatten()(NN.output)\n","x = layers.Dense(1000, activation='relu')(x)\n","prediction = layers.Dense(10, activation='softmax')(x)\n","# creating a model object\n","model = Model(inputs=NN.input, outputs=prediction)\n","sgd = tf.keras.optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n","model.compile(\n","  loss='categorical_crossentropy',\n","\n","  optimizer='sgd',\n","\n","  metrics=['accuracy'] \n","\n",")"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n","94773248/94765736 [==============================] - 1s 0us/step\n","94781440/94765736 [==============================] - 1s 0us/step\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning:\n","\n","The `lr` argument is deprecated, use `learning_rate` instead.\n","\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mecACg4VpiZN","outputId":"76a02d73-1080-418f-a8de-e7043b6f8734","executionInfo":{"status":"ok","timestamp":1646240368996,"user_tz":300,"elapsed":12782,"user":{"displayName":"yaser khamayseh","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14587607702986936428"}}},"source":["import PIL\n","X=[]\n","Y=[]\n","base_dir=\"/content/gdrive/MyDrive/MBZUAI/Smart Triage/Potential Datasets/SkinBurns\"\n","labels_list=['burns2','burns1','burns3','BacterialInfections', 'NailDiseases','ContactDermatitis','UrticariaHives','Others','wounds','ViralInfections']\n","dir=os.getcwd()\n","for directory in labels_list:\n","    print(directory)\n","    #print(len(os.listdir(base_dir+'/'+directory)))\n","    for files in os.listdir(base_dir+'/'+directory):\n","        #img = Image.open(directory+'/'+files)\n","        #img = img.convert('L')\n","        #img = img.resize((IMG_SIZE, IMG_SIZE), Image.ANTIALIAS)\n","        X.append(directory+'/'+files)\n","        #X.append([np.array(img)])\n","        current_index=labels_list.index(directory)\n","        Y.append(current_index)\n","X=np.asarray(X)\n","Y=np.asarray(Y)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["burns2\n","burns1\n","burns3\n","BacterialInfections\n","NailDiseases\n","ContactDermatitis\n","UrticariaHives\n","Others\n","wounds\n","ViralInfections\n"]}]},{"cell_type":"code","source":["!mkdir  validation\n","!mkdir  validation/burns2\n","!mkdir  validation/burns1\n","!mkdir  validation/burns3\n","!mkdir  validation/BacterialInfections\n","!mkdir  validation/NailDiseases\n","!mkdir  validation/ContactDermatitis\n","!mkdir  validation/UrticariaHives\n","!mkdir  validation/Others\n","!mkdir  validation/wounds\n","!mkdir  validation/ViralInfections"],"metadata":{"id":"mLGJM0s51nVa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!rm -r validation"],"metadata":{"id":"dCdRQgMDS_Ws"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YUHxbVIsj_T5","colab":{"base_uri":"https://localhost:8080/"},"outputId":"19e594b7-3d1f-4213-f7e4-117850aa7527","executionInfo":{"status":"ok","timestamp":1646248017842,"user_tz":300,"elapsed":7613047,"user":{"displayName":"yaser khamayseh","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14587607702986936428"}}},"source":["#kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=7)\n","cvscores = []\n","\n","validation_path=\"validation\"\n","train_path= '/content/gdrive/MyDrive/MBZUAI/Smart Triage/Potential Datasets/SkinBurns/'\n","#skf = StratifiedKFold(n_splits=2, shuffle=True)\n","#skf.get_n_splits(X, Y)\n","accuracy_list= list()\n","precision_list=list()\n","f1_list=list()\n","microprecision_list=list()\n","microf1_list=list()\n","means, mins, maxs = list(),list(),list()\n","f1means, f1mins, f1maxs = list(),list(),list()\n","microf1means, microf1mins, microf1maxs = list(),list(),list()\n","precmeans, precmins, precmaxs = list(),list(),list()\n","microprecmeans, microprecmins, microprecmaxs = list(),list(),list()\n","\n","callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=7,min_delta=.001,mode='auto')\n","foldNum=0\n","k=5\n","skf = StratifiedKFold(n_splits=k, shuffle=True)\n","\n","for train_index, val_index in skf.split(X, Y):\n","             \n","       foldNum+=1\n","       model.compile(loss='categorical_crossentropy', optimizer='sgd',  metrics=['accuracy'] )\n","       print(\"Results for fold\",foldNum)\n","       X_train, X_val = X[train_index], X[val_index]\n","       Y_train, Y_val = Y[train_index], Y[val_index]\n","       for eachindex in range(len(X_val)):\n","           shutil.move('/content/gdrive/MyDrive/MBZUAI/Smart Triage/Potential Datasets/SkinBurns/'+X_val[eachindex], \n","                    'validation/'+X_val[eachindex])\n","       \n","       #Start ImageClassification Model\n","       train_datagen = ImageDataGenerator(rotation_range=20, horizontal_flip=True,  vertical_flip=True, brightness_range=[0.7,1.2], preprocessing_function=preprocess_input)\n","\n","       validation_datagen = ImageDataGenerator( preprocessing_function=preprocess_input)\n","       train_generator = train_datagen.flow_from_directory(\n","            train_path,\n","            shuffle= True,\n","            target_size=IMAGE_SIZE,\n","            batch_size=32,\n","            subset='training')\n","       validation_generator = validation_datagen.flow_from_directory(\n","            validation_path,\n","            target_size=IMAGE_SIZE,\n","            batch_size=32,\n","            shuffle=False)  \n","       \n","       #history=\n","       model.fit(train_generator, \n","                        epochs=40,\n","                        validation_data = validation_generator,\n","                        steps_per_epoch=int(len(X_train) // batch_size),\n","                        validation_steps=int(len(X_val) // batch_size),\n","                        callbacks=[callback])\n","       predictions = model.predict(validation_generator, verbose=1)\n","       #score = model.evaluate(validation_generator,batch_size =32)\n","       #print('eval', score)\n","       yPredictions = np.argmax(predictions, axis=1)\n","       true_classes = validation_generator.classes\n","       # evaluate validation performance\n","       #print(\"***Performance on Validation data***\")\n","       accuracy=accuracy_score(true_classes, yPredictions)\n","       f1=f1_score(true_classes, yPredictions,average='macro')\n","       microf1= f1_score(true_classes, yPredictions,average='micro')\n","       precision= precision_score(true_classes, yPredictions,average='macro')\n","       microprecision= precision_score(true_classes, yPredictions,average='micro')\n","       #precision=precision_score(true_classes, yPredictions,average='weighted')\n","       #f1Score=f1_score(true_classes, yPredictions, average='weighted') \n","       #print(\"Accuracy  : {}\".format(accuracy))\n","       #print(\"Precision : {}\".format(precision))\n","       #print(\"f1Score : {}\".format(f1Score))\n","       #cm=confusion_matrix(true_classes, yPredictions)\n","       accuracy_list.append(accuracy)\n","       f1_list.append(f1)\n","       precision_list.append(precision)\n","       microf1_list.append(microf1)\n","       microprecision_list.append(microprecision)\n","       #print(cm)\n","       #valAcc, valPrec, valFScore = my_metrics(true_classes, yPredictions)\n","       for returnindex in range(len(X_val)):\n","            shutil.move('validation/'+X_val[returnindex],'/content/gdrive/MyDrive/MBZUAI/Smart Triage/Potential Datasets/SkinBurns/'+X_val[returnindex])\n","#gotta change this to F1\n","k_mean=statistics.mean(accuracy_list)\n","k_max=max(accuracy_list)\n","k_min=min(accuracy_list)\n","means.append(k_mean)\n","mins.append(k_mean - k_min)\n","maxs.append(k_max - k_mean)\n","#==================\n","f1_mean=statistics.mean(f1_list)\n","f1_max=max(f1_list)\n","f1_min=min(f1_list)\n","f1means.append(f1_mean)\n","f1mins.append(f1_mean - f1_min)\n","f1maxs.append(f1_max - f1_mean)\n","#========================\n","prec_mean=statistics.mean(precision_list)\n","prec_max=max(precision_list)\n","prec_min=min(precision_list)\n","precmeans.append(prec_mean)\n","precmins.append(prec_mean - prec_min)\n","precmaxs.append(prec_max - prec_mean)\n","#==========================\n","microprec_mean=statistics.mean(microprecision_list)\n","microprec_max=max(microprecision_list)\n","microprec_min=min(microprecision_list)\n","microprecmeans.append(microprec_mean)\n","microprecmins.append(microprec_mean - microprec_min)\n","microprecmaxs.append(microprec_max - microprec_mean)\n","#===========================\n","microf1_mean=statistics.mean(microf1_list)\n","microf1_max=max(microf1_list)\n","microf1_min=min(microf1_list)\n","microf1means.append(microf1_mean)\n","microf1mins.append(microf1_mean - microf1_min)\n","microf1maxs.append(microf1_max - microf1_mean)\n","\n","print('Image_size and batch_size')\n","print(IMAGE_SIZE,batch_size)\n","print('Minimum Accuracy')\n","print(mins)\n","print('Maximum Accuracy')\n","print(maxs)\n","print('Average Accuracy')\n","print(means)\n","#=============\n","print('Minimum macro precision')\n","print(precmins)\n","print('Maximum macro precision')\n","print(precmaxs)\n","print('Average macro precision')\n","print(precmeans)\n","#===============\n","print('Minimum macro F1')\n","print(f1mins)\n","print('Maximum macro F1')\n","print(f1maxs)\n","print('Average macro F1')\n","print(f1means)\n","#===============\n","print('Minimum micro precision')\n","print(microprecmins)\n","print('Maximum micro precision')\n","print(microprecmaxs)\n","print('Average micro precision')\n","print(microprecmeans)\n","#===============\n","print('Minimum micro F1')\n","print(microf1mins)\n","print('Maximum micro F1')\n","print(microf1maxs)\n","print('Average micro F1')\n","print(microf1means)\n","#plt.errorbar(folds, means, yerr=[mins, maxs], fmt='o')\n","# plot the ideal case in a separate color\n","#plt.plot(folds, [ideal for _ in range(len(folds))], color='r')\n","# show the plot\n","#plt.show()\n","   #model.fit_generator(train_generator, epochs=50,  verbose = 0, validation_data=test_generator)\n","\n","   #scores = model.evaluate(X[test], Y[test], verbose=0)\n","   #print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n","\n","\n"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Results for fold 1\n","Found 3082 images belonging to 10 classes.\n","Found 771 images belonging to 10 classes.\n","Epoch 1/40\n","96/96 [==============================] - 722s 7s/step - loss: 10.2837 - accuracy: 0.3007 - val_loss: 2.2246 - val_accuracy: 0.3737\n","Epoch 2/40\n","96/96 [==============================] - 83s 869ms/step - loss: 2.1645 - accuracy: 0.3561 - val_loss: 2.1503 - val_accuracy: 0.3750\n","Epoch 3/40\n","96/96 [==============================] - 83s 866ms/step - loss: 2.0772 - accuracy: 0.3593 - val_loss: 2.0927 - val_accuracy: 0.3750\n","Epoch 4/40\n","96/96 [==============================] - 83s 868ms/step - loss: 2.0395 - accuracy: 0.3636 - val_loss: 1.8086 - val_accuracy: 0.3750\n","Epoch 5/40\n","96/96 [==============================] - 83s 863ms/step - loss: 1.9460 - accuracy: 0.3584 - val_loss: 2.0147 - val_accuracy: 0.3750\n","Epoch 6/40\n","96/96 [==============================] - 83s 869ms/step - loss: 1.9743 - accuracy: 0.3682 - val_loss: 1.8226 - val_accuracy: 0.3750\n","Epoch 7/40\n","96/96 [==============================] - 84s 872ms/step - loss: 1.9663 - accuracy: 0.3728 - val_loss: 1.9491 - val_accuracy: 0.3750\n","Epoch 8/40\n","96/96 [==============================] - 83s 868ms/step - loss: 1.9371 - accuracy: 0.3754 - val_loss: 1.9234 - val_accuracy: 0.3750\n","Epoch 9/40\n","96/96 [==============================] - 83s 863ms/step - loss: 1.9168 - accuracy: 0.3734 - val_loss: 1.9286 - val_accuracy: 0.3750\n","Epoch 10/40\n","96/96 [==============================] - 84s 870ms/step - loss: 1.8997 - accuracy: 0.3728 - val_loss: 1.8883 - val_accuracy: 0.3750\n","Epoch 11/40\n","96/96 [==============================] - 83s 866ms/step - loss: 1.8723 - accuracy: 0.3741 - val_loss: 1.8216 - val_accuracy: 0.3750\n","25/25 [==============================] - 7s 263ms/step\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n"]},{"output_type":"stream","name":"stdout","text":["Results for fold 2\n","Found 3081 images belonging to 10 classes.\n","Found 772 images belonging to 10 classes.\n","Epoch 1/40\n","96/96 [==============================] - 89s 892ms/step - loss: 1.8427 - accuracy: 0.3716 - val_loss: 1.8707 - val_accuracy: 0.3763\n","Epoch 2/40\n","96/96 [==============================] - 84s 874ms/step - loss: 1.8741 - accuracy: 0.3745 - val_loss: 1.8611 - val_accuracy: 0.3763\n","Epoch 3/40\n","96/96 [==============================] - 84s 877ms/step - loss: 1.8636 - accuracy: 0.3752 - val_loss: 1.8531 - val_accuracy: 0.3763\n","Epoch 4/40\n","96/96 [==============================] - 84s 874ms/step - loss: 1.8509 - accuracy: 0.3736 - val_loss: 1.8422 - val_accuracy: 0.3763\n","Epoch 5/40\n","96/96 [==============================] - 84s 875ms/step - loss: 1.8542 - accuracy: 0.3723 - val_loss: 1.8415 - val_accuracy: 0.3763\n","Epoch 6/40\n","96/96 [==============================] - 84s 876ms/step - loss: 1.8459 - accuracy: 0.3749 - val_loss: 1.8366 - val_accuracy: 0.3763\n","Epoch 7/40\n","96/96 [==============================] - 84s 869ms/step - loss: 1.8419 - accuracy: 0.3739 - val_loss: 1.8325 - val_accuracy: 0.3763\n","Epoch 8/40\n","96/96 [==============================] - 84s 875ms/step - loss: 1.8381 - accuracy: 0.3739 - val_loss: 1.8288 - val_accuracy: 0.3763\n","Epoch 9/40\n","96/96 [==============================] - 84s 874ms/step - loss: 1.8371 - accuracy: 0.3726 - val_loss: 1.8256 - val_accuracy: 0.3763\n","Epoch 10/40\n","96/96 [==============================] - 84s 875ms/step - loss: 1.8338 - accuracy: 0.3732 - val_loss: 1.8228 - val_accuracy: 0.3763\n","Epoch 11/40\n","96/96 [==============================] - 84s 874ms/step - loss: 1.8318 - accuracy: 0.3729 - val_loss: 1.8203 - val_accuracy: 0.3763\n","Epoch 12/40\n","96/96 [==============================] - 84s 871ms/step - loss: 1.8299 - accuracy: 0.3723 - val_loss: 1.8181 - val_accuracy: 0.3763\n","Epoch 13/40\n","96/96 [==============================] - 84s 878ms/step - loss: 1.8289 - accuracy: 0.3713 - val_loss: 1.8161 - val_accuracy: 0.3763\n","Epoch 14/40\n","96/96 [==============================] - 84s 877ms/step - loss: 1.8220 - accuracy: 0.3742 - val_loss: 1.8143 - val_accuracy: 0.3763\n","Epoch 15/40\n","96/96 [==============================] - 83s 867ms/step - loss: 1.8214 - accuracy: 0.3749 - val_loss: 1.8126 - val_accuracy: 0.3763\n","Epoch 16/40\n","96/96 [==============================] - 83s 870ms/step - loss: 1.8230 - accuracy: 0.3732 - val_loss: 1.8112 - val_accuracy: 0.3763\n","Epoch 17/40\n","96/96 [==============================] - 83s 869ms/step - loss: 1.8198 - accuracy: 0.3745 - val_loss: 1.8101 - val_accuracy: 0.3763\n","Epoch 18/40\n","96/96 [==============================] - 83s 867ms/step - loss: 1.8188 - accuracy: 0.3732 - val_loss: 1.8089 - val_accuracy: 0.3763\n","Epoch 19/40\n","96/96 [==============================] - 83s 868ms/step - loss: 1.8172 - accuracy: 0.3739 - val_loss: 1.8078 - val_accuracy: 0.3763\n","Epoch 20/40\n","96/96 [==============================] - 83s 866ms/step - loss: 1.8150 - accuracy: 0.3739 - val_loss: 1.8068 - val_accuracy: 0.3763\n","Epoch 21/40\n","96/96 [==============================] - 83s 868ms/step - loss: 1.8166 - accuracy: 0.3732 - val_loss: 1.8059 - val_accuracy: 0.3763\n","Epoch 22/40\n","96/96 [==============================] - 84s 871ms/step - loss: 1.8146 - accuracy: 0.3726 - val_loss: 1.8051 - val_accuracy: 0.3763\n","Epoch 23/40\n","96/96 [==============================] - 83s 870ms/step - loss: 1.8131 - accuracy: 0.3749 - val_loss: 1.8043 - val_accuracy: 0.3763\n","Epoch 24/40\n","96/96 [==============================] - 84s 873ms/step - loss: 1.8110 - accuracy: 0.3749 - val_loss: 1.8036 - val_accuracy: 0.3763\n","Epoch 25/40\n","96/96 [==============================] - 84s 872ms/step - loss: 1.8126 - accuracy: 0.3736 - val_loss: 1.8029 - val_accuracy: 0.3763\n","Epoch 26/40\n","96/96 [==============================] - 83s 870ms/step - loss: 1.8117 - accuracy: 0.3755 - val_loss: 1.8024 - val_accuracy: 0.3763\n","Epoch 27/40\n","96/96 [==============================] - 84s 871ms/step - loss: 1.8109 - accuracy: 0.3749 - val_loss: 1.8017 - val_accuracy: 0.3763\n","Epoch 28/40\n","96/96 [==============================] - 84s 871ms/step - loss: 1.8112 - accuracy: 0.3742 - val_loss: 1.8012 - val_accuracy: 0.3763\n","Epoch 29/40\n","96/96 [==============================] - 82s 855ms/step - loss: 1.8117 - accuracy: 0.3745 - val_loss: 1.8007 - val_accuracy: 0.3763\n","Epoch 30/40\n","96/96 [==============================] - 81s 842ms/step - loss: 1.8095 - accuracy: 0.3739 - val_loss: 1.8003 - val_accuracy: 0.3763\n","Epoch 31/40\n","96/96 [==============================] - 81s 839ms/step - loss: 1.8088 - accuracy: 0.3745 - val_loss: 1.8241 - val_accuracy: 0.3763\n","Epoch 32/40\n","96/96 [==============================] - 81s 840ms/step - loss: 1.8121 - accuracy: 0.3723 - val_loss: 1.7995 - val_accuracy: 0.3763\n","Epoch 33/40\n","96/96 [==============================] - 81s 838ms/step - loss: 1.8107 - accuracy: 0.3736 - val_loss: 1.7991 - val_accuracy: 0.3763\n","Epoch 34/40\n","96/96 [==============================] - 81s 841ms/step - loss: 1.8091 - accuracy: 0.3729 - val_loss: 1.7987 - val_accuracy: 0.3763\n","Epoch 35/40\n","96/96 [==============================] - 81s 840ms/step - loss: 1.8070 - accuracy: 0.3752 - val_loss: 1.7983 - val_accuracy: 0.3763\n","Epoch 36/40\n","96/96 [==============================] - 81s 840ms/step - loss: 1.8065 - accuracy: 0.3739 - val_loss: 1.7980 - val_accuracy: 0.3763\n","Epoch 37/40\n","96/96 [==============================] - 81s 838ms/step - loss: 1.8076 - accuracy: 0.3752 - val_loss: 1.7978 - val_accuracy: 0.3763\n","Epoch 38/40\n","96/96 [==============================] - 82s 851ms/step - loss: 1.8100 - accuracy: 0.3726 - val_loss: 1.7975 - val_accuracy: 0.3763\n","Epoch 39/40\n","96/96 [==============================] - 82s 851ms/step - loss: 1.8089 - accuracy: 0.3742 - val_loss: 1.7973 - val_accuracy: 0.3763\n","Epoch 40/40\n","96/96 [==============================] - 82s 852ms/step - loss: 1.8079 - accuracy: 0.3732 - val_loss: 1.7971 - val_accuracy: 0.3763\n","25/25 [==============================] - 8s 268ms/step\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n"]},{"output_type":"stream","name":"stdout","text":["Results for fold 3\n","Found 3084 images belonging to 10 classes.\n","Found 769 images belonging to 10 classes.\n","Epoch 1/40\n","96/96 [==============================] - 87s 875ms/step - loss: 1.8075 - accuracy: 0.3739 - val_loss: 1.7994 - val_accuracy: 0.3750\n","Epoch 2/40\n","96/96 [==============================] - 82s 858ms/step - loss: 1.8080 - accuracy: 0.3748 - val_loss: 1.7992 - val_accuracy: 0.3750\n","Epoch 3/40\n","96/96 [==============================] - 82s 855ms/step - loss: 1.8073 - accuracy: 0.3742 - val_loss: 1.7990 - val_accuracy: 0.3750\n","Epoch 4/40\n","96/96 [==============================] - 82s 860ms/step - loss: 1.8075 - accuracy: 0.3748 - val_loss: 1.7988 - val_accuracy: 0.3750\n","Epoch 5/40\n","96/96 [==============================] - 82s 856ms/step - loss: 1.8091 - accuracy: 0.3745 - val_loss: 1.7987 - val_accuracy: 0.3750\n","Epoch 6/40\n","96/96 [==============================] - 81s 846ms/step - loss: 1.8101 - accuracy: 0.3739 - val_loss: 1.7985 - val_accuracy: 0.3750\n","Epoch 7/40\n","96/96 [==============================] - 82s 850ms/step - loss: 1.8081 - accuracy: 0.3735 - val_loss: 1.7982 - val_accuracy: 0.3750\n","Epoch 8/40\n","96/96 [==============================] - 81s 841ms/step - loss: 1.8079 - accuracy: 0.3725 - val_loss: 1.7983 - val_accuracy: 0.3750\n","Epoch 9/40\n","96/96 [==============================] - 81s 844ms/step - loss: 1.8117 - accuracy: 0.3719 - val_loss: 1.7981 - val_accuracy: 0.3750\n","Epoch 10/40\n","96/96 [==============================] - 81s 845ms/step - loss: 1.8083 - accuracy: 0.3739 - val_loss: 1.7980 - val_accuracy: 0.3750\n","Epoch 11/40\n","96/96 [==============================] - 81s 848ms/step - loss: 1.8047 - accuracy: 0.3739 - val_loss: 1.7979 - val_accuracy: 0.3750\n","Epoch 12/40\n","96/96 [==============================] - 81s 845ms/step - loss: 1.8059 - accuracy: 0.3742 - val_loss: 1.7977 - val_accuracy: 0.3750\n","Epoch 13/40\n","96/96 [==============================] - 81s 847ms/step - loss: 1.8078 - accuracy: 0.3739 - val_loss: 1.7977 - val_accuracy: 0.3750\n","Epoch 14/40\n","96/96 [==============================] - 82s 851ms/step - loss: 1.8078 - accuracy: 0.3739 - val_loss: 1.7976 - val_accuracy: 0.3750\n","25/25 [==============================] - 8s 269ms/step\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n"]},{"output_type":"stream","name":"stdout","text":["Results for fold 4\n","Found 3082 images belonging to 10 classes.\n","Found 771 images belonging to 10 classes.\n","Epoch 1/40\n","96/96 [==============================] - 87s 872ms/step - loss: 1.8036 - accuracy: 0.3748 - val_loss: 1.7996 - val_accuracy: 0.3750\n","Epoch 2/40\n","96/96 [==============================] - 82s 851ms/step - loss: 1.8037 - accuracy: 0.3748 - val_loss: 1.7995 - val_accuracy: 0.3750\n","Epoch 3/40\n","96/96 [==============================] - 81s 846ms/step - loss: 1.8042 - accuracy: 0.3738 - val_loss: 1.7994 - val_accuracy: 0.3750\n","Epoch 4/40\n","96/96 [==============================] - 82s 852ms/step - loss: 1.8023 - accuracy: 0.3757 - val_loss: 1.7994 - val_accuracy: 0.3750\n","Epoch 5/40\n","96/96 [==============================] - 81s 845ms/step - loss: 1.8032 - accuracy: 0.3754 - val_loss: 1.7993 - val_accuracy: 0.3750\n","Epoch 6/40\n","96/96 [==============================] - 82s 859ms/step - loss: 1.8037 - accuracy: 0.3744 - val_loss: 1.7992 - val_accuracy: 0.3750\n","Epoch 7/40\n","96/96 [==============================] - 81s 846ms/step - loss: 1.8016 - accuracy: 0.3754 - val_loss: 1.7992 - val_accuracy: 0.3750\n","Epoch 8/40\n","96/96 [==============================] - 81s 849ms/step - loss: 1.8031 - accuracy: 0.3741 - val_loss: 1.7995 - val_accuracy: 0.3750\n","25/25 [==============================] - 7s 264ms/step\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n"]},{"output_type":"stream","name":"stdout","text":["Results for fold 5\n","Found 3083 images belonging to 10 classes.\n","Found 770 images belonging to 10 classes.\n","Epoch 1/40\n","96/96 [==============================] - 87s 871ms/step - loss: 1.8055 - accuracy: 0.3746 - val_loss: 1.8012 - val_accuracy: 0.3750\n","Epoch 2/40\n","96/96 [==============================] - 81s 847ms/step - loss: 1.8038 - accuracy: 0.3733 - val_loss: 1.8011 - val_accuracy: 0.3750\n","Epoch 3/40\n","96/96 [==============================] - 82s 853ms/step - loss: 1.8032 - accuracy: 0.3753 - val_loss: 1.8011 - val_accuracy: 0.3750\n","Epoch 4/40\n","96/96 [==============================] - 82s 849ms/step - loss: 1.8044 - accuracy: 0.3736 - val_loss: 1.8011 - val_accuracy: 0.3750\n","Epoch 5/40\n","96/96 [==============================] - 81s 844ms/step - loss: 1.8040 - accuracy: 0.3740 - val_loss: 1.8011 - val_accuracy: 0.3750\n","Epoch 6/40\n","96/96 [==============================] - 81s 848ms/step - loss: 1.8060 - accuracy: 0.3736 - val_loss: 1.8010 - val_accuracy: 0.3750\n","Epoch 7/40\n","96/96 [==============================] - 81s 845ms/step - loss: 1.8037 - accuracy: 0.3733 - val_loss: 1.8009 - val_accuracy: 0.3750\n","Epoch 8/40\n","96/96 [==============================] - 81s 846ms/step - loss: 1.8005 - accuracy: 0.3759 - val_loss: 1.8008 - val_accuracy: 0.3750\n","25/25 [==============================] - 8s 281ms/step\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n"]},{"output_type":"stream","name":"stdout","text":["Image_size and batch_size\n","[250, 250] 32\n","Minimum Accuracy\n","[0.000453618248983656]\n","Maximum Accuracy\n","[0.0005178794259997899]\n","Average Accuracy\n","[0.37399447428011207]\n","Minimum macro precision\n","[4.53618248983656e-05]\n","Maximum macro precision\n","[5.178794259998176e-05]\n","Average macro precision\n","[0.037399447428011205]\n","Minimum macro F1\n","[4.805972198912434e-05]\n","Maximum macro F1\n","[5.4855954158827824e-05]\n","Average macro F1\n","[0.054438994566181766]\n","Minimum micro precision\n","[0.000453618248983656]\n","Maximum micro precision\n","[0.0005178794259997899]\n","Average micro precision\n","[0.37399447428011207]\n","Minimum micro F1\n","[0.000453618248983656]\n","Maximum micro F1\n","[0.0005178794259997344]\n","Average micro F1\n","[0.3739944742801121]\n"]}]},{"cell_type":"markdown","source":["Image_size and batch_size\n","[250, 250] 32\n","Minimum Accuracy\n","[0.000453618248983656]\n","Maximum Accuracy\n","[0.0005178794259997899]\n","Average Accuracy\n","[0.37399447428011207]\n","Minimum macro precision\n","[4.53618248983656e-05]\n","Maximum macro precision\n","[5.178794259998176e-05]\n","Average macro precision\n","[0.037399447428011205]\n","Minimum macro F1\n","[4.805972198912434e-05]\n","Maximum macro F1\n","[5.4855954158827824e-05]\n","Average macro F1\n","[0.054438994566181766]\n","Minimum micro precision\n","[0.000453618248983656]\n","Maximum micro precision\n","[0.0005178794259997899]\n","Average micro precision\n","[0.37399447428011207]\n","Minimum micro F1\n","[0.000453618248983656]\n","Maximum micro F1\n","[0.0005178794259997344]\n","Average micro F1\n","[0.3739944742801121]"],"metadata":{"id":"JyjkE2E0dU1M"}}]}