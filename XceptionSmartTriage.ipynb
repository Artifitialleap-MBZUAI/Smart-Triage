{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"XceptionSmartTriage.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"Y04rYVmZ8bwf","colab":{"base_uri":"https://localhost:8080/","height":34,"output_embedded_package_id":"1nkDOPHuZPhNXUa9vfUOtjddSgPNBF9VA"},"executionInfo":{"status":"ok","timestamp":1646248259875,"user_tz":300,"elapsed":30536,"user":{"displayName":"yaser khamayseh","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14587607702986936428"}},"outputId":"6febc176-d93c-4f57-d26c-c8c38f9add05"},"source":["import os\n","import tensorflow as tf\n","import numpy as np #adds support for large, multi-dimensional arrays and matrices, along with a large collection of high-level mathematical functions to operate on these arrays\n","import pandas as pd #data structures and operations for manipulating numerical tables and time series\n","import sys # system path io\n","import glob #glob module is used to retrieve files/pathnames matching a specified pattern\n","from tqdm import tqdm # show progress bar when a loop is running\n","from plotly.offline import download_plotlyjs, init_notebook_mode, iplot\n","from plotly import tools\n","from plotly.graph_objs import *\n","from plotly.graph_objs.layout import Margin, YAxis, XAxis\n","init_notebook_mode()\n","import matplotlib.pyplot as plt\n","from matplotlib import patches as patches\n","from pathlib import Path\n","import xml.etree.ElementTree as ET\n","from keras.callbacks import EarlyStopping\n","from sklearn.metrics import accuracy_score, f1_score, precision_score, confusion_matrix\n","from keras.applications.densenet import DenseNet121, preprocess_input\n","from keras.applications.resnet import ResNet50, preprocess_input\n","from sklearn.model_selection import KFold, StratifiedKFold\n","from keras.applications.mobilenet_v2 import MobileNetV2,preprocess_input\n","from keras.applications.xception import Xception,preprocess_input, decode_predictions\n","from keras.applications.mobilenet import MobileNet,preprocess_input\n","from keras.preprocessing import image\n","from keras.preprocessing.image import ImageDataGenerator\n","from keras import optimizers\n","from keras import backend as K\n","import io\n","from google.colab import drive\n","from sklearn.model_selection import KFold, StratifiedKFold,LeaveOneOut\n","from keras.layers import Input, Lambda, Dense, Flatten\n","from keras.models import Model\n","from keras.preprocessing import image\n","from keras.preprocessing.image import ImageDataGenerator\n","from keras import optimizers\n","from keras import backend as K\n","from keras.callbacks import EarlyStopping\n","import shutil\n","import statistics\n","from keras.models import Model\n","from tensorflow.keras import layers\n","drive.mount('/content/gdrive')\n"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","source":["#Structure: Diagnosis, Triage_Level\n","#NEED TO CODE FOR THE ZERO TRIAGE SCORE!\n","#Not real scores!\n","LookUp_Dictionary  = {\n","  'burns1':1,\n","  'burns2': 2,\n","  'burns3':10 ,\n","  'BacterialInfections': 5, \n","  'NailDiseases':2 ,\n","  'ContactDermatitis':6,\n","  'UrticariaHives':3,\n","  'Others':0,\n","  'wounds': 7,\n","  'ViralInfections':5\n","}\n","print(LookUp_Dictionary)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UbPA-ZWIS9I8","executionInfo":{"status":"ok","timestamp":1646231445898,"user_tz":300,"elapsed":12,"user":{"displayName":"yaser khamayseh","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14587607702986936428"}},"outputId":"a9fff7fd-0889-4fcb-fcb9-be546093ad7a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["{'burns1': 1, 'burns2': 2, 'burns3': 10, 'BacterialInfections': 5, 'NailDiseases': 2, 'ContactDermatitis': 6, 'UrticariaHives': 3, 'Others': 0, 'wounds': 7, 'ViralInfections': 5}\n"]}]},{"cell_type":"code","metadata":{"id":"EsjJaP62lPop","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1646248288012,"user_tz":300,"elapsed":5137,"user":{"displayName":"yaser khamayseh","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14587607702986936428"}},"outputId":"17336ffd-0de7-4311-8640-35fa3b404cc0"},"source":["IMAGE_SIZE=[250,250]\n","batch_size=32\n","NN  =  Xception(input_shape=IMAGE_SIZE + [3], weights='imagenet', include_top=False)  \n","#MobileNet(input_shape=IMAGE_SIZE + [3], weights='imagenet', include_top=False)   \n","for layer in NN.layers:\n","    layer.trainable = False\n","# layers creation - Here more can be added\n","x = layers.Flatten()(NN.output)\n","x = layers.Dense(1000, activation='relu')(x)\n","prediction = layers.Dense(10, activation='softmax')(x)\n","# creating a model object\n","model = Model(inputs=NN.input, outputs=prediction)\n","sgd = tf.keras.optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n","model.compile(\n","  loss='categorical_crossentropy',\n","\n","  optimizer='sgd',\n","\n","  metrics=['accuracy'] \n","\n",")"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/xception/xception_weights_tf_dim_ordering_tf_kernels_notop.h5\n","83689472/83683744 [==============================] - 1s 0us/step\n","83697664/83683744 [==============================] - 1s 0us/step\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning:\n","\n","The `lr` argument is deprecated, use `learning_rate` instead.\n","\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mecACg4VpiZN","outputId":"703dfb99-9956-4938-bc10-0f5a7a2824e7","executionInfo":{"status":"ok","timestamp":1646248309286,"user_tz":300,"elapsed":14826,"user":{"displayName":"yaser khamayseh","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14587607702986936428"}}},"source":["import PIL\n","X=[]\n","Y=[]\n","base_dir=\"/content/gdrive/MyDrive/MBZUAI/Smart Triage/Potential Datasets/SkinBurns\"\n","labels_list=['burns2','burns1','burns3','BacterialInfections', 'NailDiseases','ContactDermatitis','UrticariaHives','Others','wounds','ViralInfections']\n","dir=os.getcwd()\n","for directory in labels_list:\n","    print(directory)\n","    #print(len(os.listdir(base_dir+'/'+directory)))\n","    for files in os.listdir(base_dir+'/'+directory):\n","        #img = Image.open(directory+'/'+files)\n","        #img = img.convert('L')\n","        #img = img.resize((IMG_SIZE, IMG_SIZE), Image.ANTIALIAS)\n","        X.append(directory+'/'+files)\n","        #X.append([np.array(img)])\n","        current_index=labels_list.index(directory)\n","        Y.append(current_index)\n","X=np.asarray(X)\n","Y=np.asarray(Y)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["burns2\n","burns1\n","burns3\n","BacterialInfections\n","NailDiseases\n","ContactDermatitis\n","UrticariaHives\n","Others\n","wounds\n","ViralInfections\n"]}]},{"cell_type":"code","source":["!mkdir  validation\n","!mkdir  validation/burns2\n","!mkdir  validation/burns1\n","!mkdir  validation/burns3\n","!mkdir  validation/BacterialInfections\n","!mkdir  validation/NailDiseases\n","!mkdir  validation/ContactDermatitis\n","!mkdir  validation/UrticariaHives\n","!mkdir  validation/Others\n","!mkdir  validation/wounds\n","!mkdir  validation/ViralInfections"],"metadata":{"id":"mLGJM0s51nVa"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YUHxbVIsj_T5","colab":{"base_uri":"https://localhost:8080/"},"outputId":"da486cae-668a-469a-d097-939aa86564e1","executionInfo":{"status":"ok","timestamp":1646254810421,"user_tz":300,"elapsed":2029490,"user":{"displayName":"yaser khamayseh","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14587607702986936428"}}},"source":["#kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=7)\n","cvscores = []\n","\n","validation_path=\"validation\"\n","train_path= '/content/gdrive/MyDrive/MBZUAI/Smart Triage/Potential Datasets/SkinBurns/'\n","#skf = StratifiedKFold(n_splits=2, shuffle=True)\n","#skf.get_n_splits(X, Y)\n","accuracy_list= list()\n","precision_list=list()\n","f1_list=list()\n","microprecision_list=list()\n","microf1_list=list()\n","means, mins, maxs = list(),list(),list()\n","f1means, f1mins, f1maxs = list(),list(),list()\n","microf1means, microf1mins, microf1maxs = list(),list(),list()\n","precmeans, precmins, precmaxs = list(),list(),list()\n","microprecmeans, microprecmins, microprecmaxs = list(),list(),list()\n","\n","callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=7,min_delta=.001,mode='auto')\n","foldNum=0\n","k=5\n","skf = StratifiedKFold(n_splits=k, shuffle=True)\n","\n","for train_index, val_index in skf.split(X, Y):\n","             \n","       foldNum+=1\n","       model.compile(loss='categorical_crossentropy', optimizer='sgd',  metrics=['accuracy'] )\n","       print(\"Results for fold\",foldNum)\n","       X_train, X_val = X[train_index], X[val_index]\n","       Y_train, Y_val = Y[train_index], Y[val_index]\n","       for eachindex in range(len(X_val)):\n","           shutil.move('/content/gdrive/MyDrive/MBZUAI/Smart Triage/Potential Datasets/SkinBurns/'+X_val[eachindex], \n","                    'validation/'+X_val[eachindex])\n","       \n","       #Start ImageClassification Model\n","       train_datagen = ImageDataGenerator(rotation_range=20, horizontal_flip=True,  vertical_flip=True, brightness_range=[0.7,1.2], preprocessing_function=preprocess_input)\n","\n","       validation_datagen = ImageDataGenerator( preprocessing_function=preprocess_input)\n","       train_generator = train_datagen.flow_from_directory(\n","            train_path,\n","            shuffle= True,\n","            target_size=IMAGE_SIZE,\n","            batch_size=32,\n","            subset='training')\n","       validation_generator = validation_datagen.flow_from_directory(\n","            validation_path,\n","            target_size=IMAGE_SIZE,\n","            batch_size=32,\n","            shuffle=False)  \n","       \n","       #history=\n","       model.fit(train_generator, \n","                        epochs=40,\n","                        validation_data = validation_generator,\n","                        steps_per_epoch=int(len(X_train) // batch_size),\n","                        validation_steps=int(len(X_val) // batch_size),\n","                        callbacks=[callback])\n","       predictions = model.predict(validation_generator, verbose=1)\n","       #score = model.evaluate(validation_generator,batch_size =32)\n","       #print('eval', score)\n","       yPredictions = np.argmax(predictions, axis=1)\n","       true_classes = validation_generator.classes\n","       # evaluate validation performance\n","       #print(\"***Performance on Validation data***\")\n","       accuracy=accuracy_score(true_classes, yPredictions)\n","       f1=f1_score(true_classes, yPredictions,average='macro')\n","       microf1= f1_score(true_classes, yPredictions,average='micro')\n","       precision= precision_score(true_classes, yPredictions,average='macro')\n","       microprecision= precision_score(true_classes, yPredictions,average='micro')\n","       #precision=precision_score(true_classes, yPredictions,average='weighted')\n","       #f1Score=f1_score(true_classes, yPredictions, average='weighted') \n","       #print(\"Accuracy  : {}\".format(accuracy))\n","       #print(\"Precision : {}\".format(precision))\n","       #print(\"f1Score : {}\".format(f1Score))\n","       #cm=confusion_matrix(true_classes, yPredictions)\n","       accuracy_list.append(accuracy)\n","       f1_list.append(f1)\n","       precision_list.append(precision)\n","       microf1_list.append(microf1)\n","       microprecision_list.append(microprecision)\n","       #print(cm)\n","       #valAcc, valPrec, valFScore = my_metrics(true_classes, yPredictions)\n","       for returnindex in range(len(X_val)):\n","            shutil.move('validation/'+X_val[returnindex],'/content/gdrive/MyDrive/MBZUAI/Smart Triage/Potential Datasets/SkinBurns/'+X_val[returnindex])\n","#gotta change this to F1\n","k_mean=statistics.mean(accuracy_list)\n","k_max=max(accuracy_list)\n","k_min=min(accuracy_list)\n","means.append(k_mean)\n","mins.append(k_mean - k_min)\n","maxs.append(k_max - k_mean)\n","#==================\n","f1_mean=statistics.mean(f1_list)\n","f1_max=max(f1_list)\n","f1_min=min(f1_list)\n","f1means.append(f1_mean)\n","f1mins.append(f1_mean - f1_min)\n","f1maxs.append(f1_max - f1_mean)\n","#========================\n","prec_mean=statistics.mean(precision_list)\n","prec_max=max(precision_list)\n","prec_min=min(precision_list)\n","precmeans.append(prec_mean)\n","precmins.append(prec_mean - prec_min)\n","precmaxs.append(prec_max - prec_mean)\n","#==========================\n","microprec_mean=statistics.mean(microprecision_list)\n","microprec_max=max(microprecision_list)\n","microprec_min=min(microprecision_list)\n","microprecmeans.append(microprec_mean)\n","microprecmins.append(microprec_mean - microprec_min)\n","microprecmaxs.append(microprec_max - microprec_mean)\n","#===========================\n","microf1_mean=statistics.mean(microf1_list)\n","microf1_max=max(microf1_list)\n","microf1_min=min(microf1_list)\n","microf1means.append(microf1_mean)\n","microf1mins.append(microf1_mean - microf1_min)\n","microf1maxs.append(microf1_max - microf1_mean)\n","\n","print('Image_size and batch_size')\n","print(IMAGE_SIZE,batch_size)\n","print('Minimum Accuracy')\n","print(mins)\n","print('Maximum Accuracy')\n","print(maxs)\n","print('Average Accuracy')\n","print(means)\n","#=============\n","print('Minimum macro precision')\n","print(precmins)\n","print('Maximum macro precision')\n","print(precmaxs)\n","print('Average macro precision')\n","print(precmeans)\n","#===============\n","print('Minimum macro F1')\n","print(f1mins)\n","print('Maximum macro F1')\n","print(f1maxs)\n","print('Average macro F1')\n","print(f1means)\n","#===============\n","print('Minimum micro precision')\n","print(microprecmins)\n","print('Maximum micro precision')\n","print(microprecmaxs)\n","print('Average micro precision')\n","print(microprecmeans)\n","#===============\n","print('Minimum micro F1')\n","print(microf1mins)\n","print('Maximum micro F1')\n","print(microf1maxs)\n","print('Average micro F1')\n","print(microf1means)\n","#plt.errorbar(folds, means, yerr=[mins, maxs], fmt='o')\n","# plot the ideal case in a separate color\n","#plt.plot(folds, [ideal for _ in range(len(folds))], color='r')\n","# show the plot\n","#plt.show()\n","   #model.fit_generator(train_generator, epochs=50,  verbose = 0, validation_data=test_generator)\n","\n","   #scores = model.evaluate(X[test], Y[test], verbose=0)\n","   #print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n","\n","\n"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Results for fold 1\n","Found 3081 images belonging to 10 classes.\n","Found 772 images belonging to 10 classes.\n","Epoch 1/40\n","96/96 [==============================] - 1631s 17s/step - loss: 1.3606 - accuracy: 0.5536 - val_loss: 0.9498 - val_accuracy: 0.6419\n","Epoch 2/40\n","96/96 [==============================] - 78s 813ms/step - loss: 0.8666 - accuracy: 0.6655 - val_loss: 0.8894 - val_accuracy: 0.6654\n","Epoch 3/40\n","96/96 [==============================] - 78s 811ms/step - loss: 0.7447 - accuracy: 0.7156 - val_loss: 0.8150 - val_accuracy: 0.6836\n","Epoch 4/40\n","96/96 [==============================] - 78s 815ms/step - loss: 0.6869 - accuracy: 0.7402 - val_loss: 0.7621 - val_accuracy: 0.7031\n","Epoch 5/40\n","96/96 [==============================] - 78s 811ms/step - loss: 0.6384 - accuracy: 0.7557 - val_loss: 0.7388 - val_accuracy: 0.7070\n","Epoch 6/40\n","96/96 [==============================] - 78s 811ms/step - loss: 0.5946 - accuracy: 0.7707 - val_loss: 0.7628 - val_accuracy: 0.6966\n","Epoch 7/40\n","96/96 [==============================] - 78s 813ms/step - loss: 0.5408 - accuracy: 0.8042 - val_loss: 0.7213 - val_accuracy: 0.7201\n","Epoch 8/40\n","96/96 [==============================] - 78s 813ms/step - loss: 0.5058 - accuracy: 0.8055 - val_loss: 0.7755 - val_accuracy: 0.6966\n","Epoch 9/40\n","96/96 [==============================] - 78s 812ms/step - loss: 0.4970 - accuracy: 0.8085 - val_loss: 0.6939 - val_accuracy: 0.7266\n","Epoch 10/40\n","96/96 [==============================] - 78s 817ms/step - loss: 0.4383 - accuracy: 0.8383 - val_loss: 0.7844 - val_accuracy: 0.7044\n","Epoch 11/40\n","96/96 [==============================] - 78s 811ms/step - loss: 0.4435 - accuracy: 0.8298 - val_loss: 0.6950 - val_accuracy: 0.7370\n","Epoch 12/40\n","96/96 [==============================] - 78s 811ms/step - loss: 0.3909 - accuracy: 0.8534 - val_loss: 0.7407 - val_accuracy: 0.7148\n","Epoch 13/40\n","96/96 [==============================] - 78s 806ms/step - loss: 0.3924 - accuracy: 0.8488 - val_loss: 0.7191 - val_accuracy: 0.7253\n","Epoch 14/40\n","96/96 [==============================] - 78s 811ms/step - loss: 0.3529 - accuracy: 0.8682 - val_loss: 0.8732 - val_accuracy: 0.6862\n","Epoch 15/40\n","96/96 [==============================] - 78s 811ms/step - loss: 0.3297 - accuracy: 0.8786 - val_loss: 0.7363 - val_accuracy: 0.7279\n","Epoch 16/40\n","96/96 [==============================] - 78s 810ms/step - loss: 0.3093 - accuracy: 0.8865 - val_loss: 0.8031 - val_accuracy: 0.7214\n","25/25 [==============================] - 7s 258ms/step\n","Results for fold 2\n","Found 3083 images belonging to 10 classes.\n","Found 770 images belonging to 10 classes.\n","Epoch 1/40\n","96/96 [==============================] - 83s 830ms/step - loss: 0.4400 - accuracy: 0.8391 - val_loss: 0.3089 - val_accuracy: 0.8984\n","Epoch 2/40\n","96/96 [==============================] - 79s 819ms/step - loss: 0.4028 - accuracy: 0.8496 - val_loss: 0.3184 - val_accuracy: 0.8984\n","Epoch 3/40\n","96/96 [==============================] - 79s 818ms/step - loss: 0.3621 - accuracy: 0.8722 - val_loss: 0.3170 - val_accuracy: 0.8815\n","Epoch 4/40\n","96/96 [==============================] - 79s 822ms/step - loss: 0.3496 - accuracy: 0.8679 - val_loss: 0.3160 - val_accuracy: 0.8802\n","Epoch 5/40\n","96/96 [==============================] - 78s 812ms/step - loss: 0.3094 - accuracy: 0.8915 - val_loss: 0.3157 - val_accuracy: 0.8893\n","Epoch 6/40\n","96/96 [==============================] - 78s 808ms/step - loss: 0.2884 - accuracy: 0.9000 - val_loss: 0.3005 - val_accuracy: 0.8919\n","Epoch 7/40\n","96/96 [==============================] - 78s 815ms/step - loss: 0.2680 - accuracy: 0.9010 - val_loss: 0.3468 - val_accuracy: 0.8802\n","Epoch 8/40\n","96/96 [==============================] - 77s 807ms/step - loss: 0.2690 - accuracy: 0.9092 - val_loss: 0.3948 - val_accuracy: 0.8620\n","Epoch 9/40\n","96/96 [==============================] - 77s 806ms/step - loss: 0.2490 - accuracy: 0.9131 - val_loss: 0.3798 - val_accuracy: 0.8685\n","Epoch 10/40\n","96/96 [==============================] - 78s 808ms/step - loss: 0.2497 - accuracy: 0.9122 - val_loss: 0.3252 - val_accuracy: 0.8854\n","Epoch 11/40\n","96/96 [==============================] - 78s 814ms/step - loss: 0.2125 - accuracy: 0.9233 - val_loss: 0.3484 - val_accuracy: 0.8906\n","Epoch 12/40\n","96/96 [==============================] - 78s 813ms/step - loss: 0.2008 - accuracy: 0.9312 - val_loss: 0.3739 - val_accuracy: 0.8750\n","Epoch 13/40\n","96/96 [==============================] - 77s 804ms/step - loss: 0.1886 - accuracy: 0.9348 - val_loss: 0.3399 - val_accuracy: 0.8828\n","25/25 [==============================] - 7s 260ms/step\n","Results for fold 3\n","Found 3082 images belonging to 10 classes.\n","Found 771 images belonging to 10 classes.\n","Epoch 1/40\n","96/96 [==============================] - 82s 823ms/step - loss: 0.2550 - accuracy: 0.9102 - val_loss: 0.1859 - val_accuracy: 0.9271\n","Epoch 2/40\n","96/96 [==============================] - 78s 815ms/step - loss: 0.2174 - accuracy: 0.9216 - val_loss: 0.1643 - val_accuracy: 0.9505\n","Epoch 3/40\n","96/96 [==============================] - 79s 819ms/step - loss: 0.1916 - accuracy: 0.9344 - val_loss: 0.1832 - val_accuracy: 0.9375\n","Epoch 4/40\n","96/96 [==============================] - 78s 808ms/step - loss: 0.2305 - accuracy: 0.9177 - val_loss: 0.1679 - val_accuracy: 0.9440\n","Epoch 5/40\n","96/96 [==============================] - 77s 806ms/step - loss: 0.1936 - accuracy: 0.9400 - val_loss: 0.1961 - val_accuracy: 0.9323\n","Epoch 6/40\n","96/96 [==============================] - 79s 822ms/step - loss: 0.1649 - accuracy: 0.9433 - val_loss: 0.1736 - val_accuracy: 0.9388\n","Epoch 7/40\n","96/96 [==============================] - 78s 808ms/step - loss: 0.1577 - accuracy: 0.9449 - val_loss: 0.2235 - val_accuracy: 0.9206\n","Epoch 8/40\n","96/96 [==============================] - 78s 813ms/step - loss: 0.1551 - accuracy: 0.9482 - val_loss: 0.2542 - val_accuracy: 0.9076\n","Epoch 9/40\n","96/96 [==============================] - 78s 812ms/step - loss: 0.1350 - accuracy: 0.9567 - val_loss: 0.1939 - val_accuracy: 0.9427\n","25/25 [==============================] - 7s 249ms/step\n","Results for fold 4\n","Found 3084 images belonging to 10 classes.\n","Found 769 images belonging to 10 classes.\n","Epoch 1/40\n","96/96 [==============================] - 83s 832ms/step - loss: 0.1768 - accuracy: 0.9391 - val_loss: 0.1653 - val_accuracy: 0.9453\n","Epoch 2/40\n","96/96 [==============================] - 78s 814ms/step - loss: 0.1414 - accuracy: 0.9548 - val_loss: 0.1882 - val_accuracy: 0.9388\n","Epoch 3/40\n","96/96 [==============================] - 78s 811ms/step - loss: 0.1471 - accuracy: 0.9528 - val_loss: 0.1499 - val_accuracy: 0.9492\n","Epoch 4/40\n","96/96 [==============================] - 78s 812ms/step - loss: 0.1488 - accuracy: 0.9505 - val_loss: 0.1904 - val_accuracy: 0.9323\n","Epoch 5/40\n","96/96 [==============================] - 78s 810ms/step - loss: 0.1218 - accuracy: 0.9656 - val_loss: 0.1850 - val_accuracy: 0.9388\n","Epoch 6/40\n","96/96 [==============================] - 78s 813ms/step - loss: 0.1153 - accuracy: 0.9659 - val_loss: 0.1698 - val_accuracy: 0.9479\n","Epoch 7/40\n","96/96 [==============================] - 79s 827ms/step - loss: 0.1326 - accuracy: 0.9551 - val_loss: 0.1526 - val_accuracy: 0.9453\n","Epoch 8/40\n","96/96 [==============================] - 79s 819ms/step - loss: 0.1083 - accuracy: 0.9663 - val_loss: 0.1639 - val_accuracy: 0.9375\n","Epoch 9/40\n","96/96 [==============================] - 79s 821ms/step - loss: 0.1042 - accuracy: 0.9663 - val_loss: 0.1792 - val_accuracy: 0.9453\n","Epoch 10/40\n","96/96 [==============================] - 78s 817ms/step - loss: 0.0933 - accuracy: 0.9718 - val_loss: 0.1557 - val_accuracy: 0.9544\n","25/25 [==============================] - 7s 262ms/step\n","Results for fold 5\n","Found 3082 images belonging to 10 classes.\n","Found 771 images belonging to 10 classes.\n","Epoch 1/40\n","96/96 [==============================] - 82s 826ms/step - loss: 0.1198 - accuracy: 0.9590 - val_loss: 0.0764 - val_accuracy: 0.9818\n","Epoch 2/40\n","96/96 [==============================] - 79s 824ms/step - loss: 0.1230 - accuracy: 0.9623 - val_loss: 0.0906 - val_accuracy: 0.9766\n","Epoch 3/40\n","96/96 [==============================] - 78s 811ms/step - loss: 0.1053 - accuracy: 0.9649 - val_loss: 0.0907 - val_accuracy: 0.9727\n","Epoch 4/40\n","96/96 [==============================] - 78s 814ms/step - loss: 0.0978 - accuracy: 0.9672 - val_loss: 0.1068 - val_accuracy: 0.9688\n","Epoch 5/40\n","96/96 [==============================] - 78s 817ms/step - loss: 0.0956 - accuracy: 0.9698 - val_loss: 0.1024 - val_accuracy: 0.9609\n","Epoch 6/40\n","96/96 [==============================] - 78s 812ms/step - loss: 0.0943 - accuracy: 0.9685 - val_loss: 0.1097 - val_accuracy: 0.9609\n","Epoch 7/40\n","96/96 [==============================] - 79s 817ms/step - loss: 0.0915 - accuracy: 0.9721 - val_loss: 0.1391 - val_accuracy: 0.9518\n","Epoch 8/40\n","96/96 [==============================] - 78s 814ms/step - loss: 0.0787 - accuracy: 0.9754 - val_loss: 0.1090 - val_accuracy: 0.9661\n","25/25 [==============================] - 7s 251ms/step\n","Image_size and batch_size\n","[250, 250] 32\n","Minimum Accuracy\n","[0.17112406777815015]\n","Maximum Accuracy\n","[0.07235556636901086]\n","Average Accuracy\n","[0.8939219952392901]\n","Minimum macro precision\n","[0.19680308404138358]\n","Maximum macro precision\n","[0.06899978513072047]\n","Average macro precision\n","[0.9033627351892217]\n","Minimum macro F1\n","[0.21613995690893129]\n","Maximum macro F1\n","[0.07684116164543553]\n","Average macro F1\n","[0.8905395817103611]\n","Minimum micro precision\n","[0.17112406777815015]\n","Maximum micro precision\n","[0.07235556636901086]\n","Average micro precision\n","[0.8939219952392901]\n","Minimum micro F1\n","[0.17112406777815015]\n","Maximum micro F1\n","[0.07235556636901086]\n","Average micro F1\n","[0.8939219952392901]\n"]}]},{"cell_type":"markdown","source":["Image_size and batch_size\n","[250, 250] 32\n","Minimum Accuracy\n","[0.17112406777815015]\n","Maximum Accuracy\n","[0.07235556636901086]\n","Average Accuracy\n","[0.8939219952392901]\n","Minimum macro precision\n","[0.19680308404138358]\n","Maximum macro precision\n","[0.06899978513072047]\n","Average macro precision\n","[0.9033627351892217]\n","Minimum macro F1\n","[0.21613995690893129]\n","Maximum macro F1\n","[0.07684116164543553]\n","Average macro F1\n","[0.8905395817103611]\n","Minimum micro precision\n","[0.17112406777815015]\n","Maximum micro precision\n","[0.07235556636901086]\n","Average micro precision\n","[0.8939219952392901]\n","Minimum micro F1\n","[0.17112406777815015]\n","Maximum micro F1\n","[0.07235556636901086]\n","Average micro F1\n","[0.8939219952392901]\n"],"metadata":{"id":"IDZUTjtndYTS"}}]}